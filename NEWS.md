# DO.utils (development version)

## REMOVE????
* Added execution of SPARQL queries, powered by python rdflib wrapper `py_rdf`.
    * `py_rdf$read()` to read in an RDF file.
    * `py_rdf$sparql_query()` to execute a SPARQL query.

## Data
* Added DO Nucleic Acids Research 2022 publication data to `DO_pubs`.

## Dependencies
* R packages:
    * `reticulate` >= v1.23 required.
    * Bug fixes needed due to changes in latest `tidyr` release (v1.2.0).
* Python dependency: `pyDOID`

## General Purpose
* Add `collapse_col_flex()` to collapse data frame columns more flexibly.
    * Adds two new methods beyond "unique": "first" & "last".
    * Adds the ability to collapse columns using different methods.
* Added wrapper functions for `pyDOID` classes
    * `DOrepo()` wraps the `pyDOID.repo.DOrepo` class
    * `owl_xml()` wraps the `pyDOID.owl.xml` class

## Graphics / Website
* Added saturated color versions to `DO_colors` (names prefixed with `sat_`).
* Created `ggplot2` plotting theme for DO, `theme_DO()`.
* Updated `plot_citedby()` to a stacked bar chart showing publication types.
* Created `plot_def_src()` to display the number of times a source is used to
    support disease definitions in the ontology (designed for
    disease-ontology.org/about/statistics).
* Functions generating html have been updated to match html style guide standards.

## Cited by
* Renamed:
    * `match_citations_fz()` to `match_fz()`
    * `concat_pm_citation()` to `read_pubmed_txt()`
* Created:
    * `pmc_summary()`
    * `hoist_ArticleIds()` (internal) - tidies PubMed/PMC identifiers
        * `tidy_ArticleId_set()` (internal)
    * `as_tibble()`, method `esummary_list_nested`
* Updated `match_citations()` to utilize Scopus EIDs.

## URLs
* Added functions to read the doid-edit.owl file and extract URLs (+ helpers).
    * `read_doid_edit()`
    * `extract_doid_url()`
* Added functions designed for URL validation.
    * `validate_url()` + helpers
    * helpers for robots.txt respectful validation _[INCOMPLETE]_


# DO.utils 0.1.7

* Setup package to wrap python via `reticulate` package.
* Added functionality to predict mappings using GILDA grounding (a type of
  lexical string matching/natural entity recognition) via python and the python
  modules `pyobo`, `indra`, and `gilda`. New functions:
    * `pyobo_map()` to create the predicted mappings.
    * `parse_mapping()` to parse the python.gilda.ScoredMatch results object to
      a list of data frames with matches (1 df/input term).
    * `unnest_mapping()` to unnest a list column generated by `pyobo_map()`
      inside a `dplyr::mutate()` call; wraps `parse_maping()`.


# DO.utils 0.1.6

## General
* Added **DEPENDENCIES** on `ggplot2`, `googlesheets4`, and `glue`.
* Renamed `match_citations_fz()` to `match_fz()`.
* Added `cast_to_string()`, a more generalized version of `vctr_to_string()`
    that accepts multiple inputs (similar to `paste()`).
* Added function to `partition()` vectors into groups with `n` elements per
    group.

## Data
* Added latest official DO publication to `DO_pubs`.
* Added official `DO_colors`.

## Feature: Website Updates
* Added functions to create statistics graphs: `plot_citedby()`,
    `plot_terms_def_counts()`, `plot_branch_counts()`, `plot_xref_counts()`.
* Added `make_user_list_html()` to create rows of table in Community >
    Collaborators > Users of the Disease Ontology from the DO team's curated
    "Uses" Google sheet.

## Internal Use Only
* Added `to_character()`, helper for `cast_to_string()`, to reduce lists and
    data frames to character vectors while limiting data loss.
* Added `html_in_rows()`, helper for `make_user_list_html()`, to format html
    elements in rows (with optional row & cell attributes).
* Added Google sheets identifiers for programmatic access.



# DO.utils 0.1.5

## General
* Added a `NEWS.md` file to track changes to the package.
* Created/updated various **helpers to manage data** (get it, make it easier to
  save/track with version control):
    * `download_file()` to flexibly handle multiple downloads.
        * Created `download_status` Ref Class to manage downloads based on exit
          code/status.
    * `confine_list()` / `release_list()` to reversibly convert a list column to a
      character vector (using json).
    * `is_invariant()` to test for vectors with only 1 value; with methods for
      character & numeric vectors.
    * `unique_to_string()` to collapse vectors to strings.
    * `unique_if_invariant()` to _conditionally_ collapse vectors with only 1
      value.
    * Added `na.rm` argument to all vctr_to_scalar functions.
    * `replace_*()`
        * `NA`, method for lists.
        * `NULL`, to replace NULL values in lists recursively.
        * `blank`, to replace "" values.
    * `collapse_col()` to collapse 1 or more specified columns in a data frame
      by concatenating unique values together, while preserving unique values in         all other columns.
* Created `download_obo_ontology()` to download 1 or more ontologies maintained
  by the OBO Foundry.

## Data
* Added more to DO publication info.
* Added OBO Foundry metadata.

## Feature: Alliance
* Made it possible to count Alliance terms for a subset of DOIDs.
* Increased record type count options (arg: record_lvl) --> "full_record",
"disease-object", "disease", "object"

## Feature: citedby
* **Created `citedby_scopus()`** to get cited by publication data from Scopus
  API, along with s3 classes & methods to manage Scopus data.
    * Updated to capture datetime citedby data is first retrieved.
* Renamed `citedby_pubmed()` to `citedby_pmid()` to reflect its output.
    * **NEED** new `citedby_pubmed()` that combines `citedby_pmid()` &
      `pubmed_summary()`.
* Modified `pubmed_summary()` to accept PMID lists as input.
    * Uses new `extract_pmid()` `elink_list` method.
* Changed citedby `tidy()` methods to `as_tibble()` methods & added new methods.
* Created `truncate_authors()` to shorten long PubMed author lists.
* Created `get_url()` & `append_to_url()` to build DOI, PubMed, and PMC URLs for
  individual publications.
